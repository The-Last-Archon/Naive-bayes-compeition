{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Implementation**\n\n**Representation of text / Preprocessing:**\nI have started by using a multinomial naïve bayes classifier, this means the frequency of occurrence of each word will be recorded instead of a Boolean expression.\n I have also decided to use all words instead of top 1000 words so that some informative words are not missed out. \nFor the multinomial version, I created 4 dictionaries based on the corresponding class. Each dictionary has words that occurred as key and frequency of occurrence as value. \nFor the complement version, I created one dictionary of dictionary where each word is a key and values are another dictionary that has 4 keys corresponding to 4 classes and the value is the count  of this word occurring in document of each type.\nIt was found that removing common words had no significant effect on performance, therefore we did not remove the common words. \n\n**Using logarithm:**\nTo handle the underflow problem (multiplying many small floating numbers and receive 0), I have decided to apply a simple log-transformation to the probabilities and the final probability will be the sum of all log-probabilities. The final predicted value will be the class with highest log-probability.The log transform is also necessary later on when I implement the complement version of naïve bayes classifier.\n\n**Laplacian smoothing:**\nThere will be words that are not being recorded in the frequency dictionary (i.e. with a frequency of 0). Since we cannot log-transform 0 and having 0 multiplied by other probabilities will leave everything as 0. I decided to add 1 to all word frequencies so that we have a minimum frequency of 1 and there will be no 0 probabilities. \n\n**Method extension**\n\n*TF-IDF Document frequency normalization:*\nIt is obvious that if a word appears in every text, it would be useless for prediction. Whereas high informative words only appear in small number of texts. A TF-IDF document frequency normalization was used such all word frequency has been multiplied by the IDF value of that word. Some rare words would have higher IDF value and common words have lower IDF value. This improvement is aimed to increase the weight of those rarely occurred words so that we do not miss any important information.\n\n*Complement Naïve bayes:*\nThe training dataset we received is heavily imbalanced. There are 2144 rows of class e, 1602 rows of class b and only around 100 rows for class a and class v. From “Tackling the Poor Assumptions of Naive Bayes Text Classifiers” We know that a complement naïve bayes would perform better than a multinomial naïve bayes on some imbalanced dataset. Therefore, we have attempted to implement a complement version of naïve bayes classifier. \n\n**Evaluation**\nI have split the training data into training and validation set. The size of training set is 70% of all data and 30% of data are used for testing. \nFor the multinomial version: We obtained an accuracy of 0.97775 when the entire dataset was used and 0.94 on the validation set. We obtained an accuracy of 0.9533 on Kaggle.\nFor TF-IDF improved version, we obtained an accuracy of 0.99025 when the entire dataset was used and 0.944 on the validation set. We obtained an accuracy of 0.94 on Kaggle.\nFor the complement version, We obtained an accuracy of 0.99225 when the entire dataset was used and 0.948 on the validation set. We obtained an accuracy of 0.96 on Kaggle, this is our best score. \nLastly, for the complement + TF-IDF version we obtained an accuracy as high as 0.9975 when the entire dataset was used and 0.954 on the validation set. However, we only obtained 0.9566 on Kaggle, which is a very minor improvement from the multinomial version. \n\n**Conclusion**\nIt is clear that any implementation/extension of naïve bayes classifier preforms far better than the ZeroR model (predicting everything as the majority class) which has an accuracy of 51.3% on Kaggle.  \nAll of the extensions had better performance than the standard naïve bayes classifier which had an accuracy of around 92%. \nI found that the complement version had a significant improvement than the multinomial version, this is not a surprise because we did have very imbalanced class. \nAfter also using TF-IDF (Document frequency normalization) on the complement version, the performance on the validation set was increased very slightly. The effect of Document frequency normalization was rather insignificant on the unseen dataset, but it does have a significant effect on the training dataset. \nOverall, the complement + TF-IDF version did have a noticeable higher accuracy than standard naïve bayes model and a much higher accuracy than the majority model. However, the effect of TF-IDF was not obvious, it is possible that this method caused some overfitting. \nOur best score was 0.96 on Kaggle, from the complement class version.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport csv \nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import files\nX = []\ny = []\nX_test = []\nwith open(\"/kaggle/input/naive-bayes/trg.csv\", 'r') as file:\n    reader = csv.reader(file)\n    for data in reader:\n        y.append(data[1])\n        X.append(data[2])\nX = X[1:]\ny = y[1:]\n\nwith open(\"/kaggle/input/naive-bayes/tst.csv\", 'r') as file:\n    reader = csv.reader(file)\n    for data in reader:\n        X_test.append(data[1])\nX_test = X_test[1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TF-IDF improved Version\ndef train(X,y):\n    # Obtain posterior probability with dictionaries by class\n    dict_a = {}\n    dict_b = {}\n    dict_v = {}\n    dict_e = {}\n    \n    # Obtain number of each class\n    count_a = 0\n    count_b = 0\n    count_v = 0\n    count_e = 0\n    unique = {}\n\n    # Obtain number of words in each class\n    count_dict = {\"A\":0, \"B\":0, \"E\":0, \"V\":0}\n\n    for i in range(len(X)):\n        word_li = X[i].split()\n        if y[i] == \"A\":\n            count_a += 1\n            for word in word_li:\n                count_dict[\"A\"] += 1\n                if word not in dict_a:\n                    dict_a[word] = 1\n                else:\n                    dict_a[word]+=1\n                if word not in unique:\n                    unique[word] = np.zeros((4000,), dtype=int)\n                    unique[word][i] = 1\n                else:\n                    if unique[word][i] == 0:\n                        unique[word][i] = 1\n\n        elif y[i] == \"B\":\n            count_b += 1\n            for word in word_li:\n                count_dict[\"B\"] += 1\n                if word not in dict_b:\n                    dict_b[word] = 1\n                else:\n                    dict_b[word] +=1\n                if word not in unique:\n                    unique[word] = np.zeros((4000,), dtype=int)\n                    unique[word][i] = 1\n                else:\n                    if unique[word][i] == 0:\n                        unique[word][i] = 1\n\n        elif y[i] == \"E\":\n            count_e += 1\n            for word in word_li:\n                count_dict[\"E\"] += 1\n                if word not in dict_e:\n                    dict_e[word] = 1\n                else:\n                    dict_e[word] += 1 \n                if word not in unique:\n                    unique[word] = np.zeros((4000,), dtype=int)\n                    unique[word][i] = 1\n                else:\n                    if unique[word][i] == 0:\n                        unique[word][i] = 1\n\n        elif y[i] == \"V\":\n            count_v += 1\n            for word in word_li:\n                count_dict[\"V\"] += 1\n                if word not in dict_v:\n                    dict_v[word] = 1\n                else:\n                    dict_v[word]+=1 \n                if word not in unique:\n                    unique[word] = np.zeros((4000,), dtype=int)\n                    unique[word][i] = 1\n                else:\n                    if unique[word][i] == 0:\n                        unique[word][i] = 1\n    # Obtain Prior Probability of Classes\n    prior_dict = {}\n    prior_dict[\"A\"] = math.log(count_a / len(X))\n    prior_dict[\"B\"] = math.log(count_b / len(X))\n    prior_dict[\"V\"] = math.log(count_v / len(X))\n    prior_dict[\"E\"] = math.log(count_e / len(X))\n    \n    return prior_dict, dict_a, dict_b, dict_v, dict_e, unique, count_dict\n\ndef predict(X, prior_dict, dict_a, dict_b, dict_v, dict_e, unique, count_dict):\n    # Predicting outcomes \n    outcome = [[] for x in range(len(X))]\n    target = [\"A\", \"B\", \"E\", \"V\"]\n    for i in range(len(X)):\n        P_AX = prior_dict[\"A\"]\n        P_BX = prior_dict[\"B\"]\n        P_EX = prior_dict[\"E\"]\n        P_VX = prior_dict[\"V\"]\n        unseen = 0\n        for word in X[i].split():\n            if word not in unique:\n                unseen += 1\n            if word in dict_a:\n                P_AX = P_AX + math.log((dict_a[word]*math.log(4000/unique[word].sum())+1) / (count_dict[\"A\"]+ len(unique) + unseen))\n            else:\n                P_AX = P_AX + math.log(1/(count_dict[\"A\"] + len(unique)+ unseen))\n\n            if word in dict_b:\n                P_BX = P_BX + math.log((dict_b[word]*math.log(4000/unique[word].sum())+1) / (count_dict[\"B\"]+ len(unique) + unseen))\n            else:\n                P_BX = P_BX + math.log(1/(count_dict[\"B\"] + len(unique)+ unseen))\n\n            if word in dict_e:\n                P_EX = P_EX + math.log((dict_e[word]*math.log(4000/unique[word].sum())+1) / (count_dict[\"E\"]+ len(unique) + unseen))\n            else:\n                P_EX = P_EX + math.log(1/(count_dict[\"E\"] + len(unique) + unseen))\n\n            if word in dict_v:\n                P_VX = P_VX + math.log((dict_v[word]*math.log(4000/unique[word].sum())+1)/(count_dict[\"V\"]+ len(unique) + unseen))\n            else:\n                P_VX = P_VX + math.log(1/(count_dict[\"V\"] + len(unique) + unseen))\n\n        probs = [P_AX, P_BX, P_EX, P_VX]\n        outcome[i] = target[probs.index(max(probs))]\n    return outcome\n\ndef evaluate(result, y):\n    score = len(y)\n    for i in range(len(y)):\n        if result[i] != y[i]:\n            score -= 1\n    return score/len(y)\n\n# Evaluation\nind = round(len(X)*0.7)\nX_train = X[:ind]\nX_val = X[ind:]\ny_train = y[:ind]\ny_val = y[ind:]\n\nprior_dict, dict_a, dict_b, dict_v, dict_e, unique, count_dict = train(X_train, y_train)\nresult = predict(X_val, prior_dict, dict_a, dict_b, dict_v, dict_e, unique, count_dict)\nevaluate(result, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multinomial version\ndef train(X,y):\n    # Obtain posterior probability\n    dict_a = {}\n    dict_b = {}\n    dict_v = {}\n    dict_e = {}\n    \n    # Obtain number of each class\n    count_a = 0\n    count_b = 0\n    count_v = 0\n    count_e = 0\n    unique = {}\n\n    # Obtain number of words in each class\n    count_dict = {\"A\":0, \"B\":0, \"E\":0, \"V\":0}\n\n    for i in range(len(X)):\n        word_li = X[i].split()\n        if y[i] == \"A\":\n            count_a += 1\n            for word in word_li:\n                count_dict[\"A\"] += 1\n                if word not in dict_a:\n                    dict_a[word] = 1\n                else:\n                    dict_a[word]+=1\n                if word not in unique:\n                    unique[word] = 1\n                else:\n                    unique[word] += 1\n\n        elif y[i] == \"B\":\n            count_b += 1\n            for word in word_li:\n                count_dict[\"B\"] += 1\n                if word not in dict_b:\n                    dict_b[word] = 1\n                else:\n                    dict_b[word] +=1\n                if word not in unique:\n                    unique[word] = 1\n                else:\n                    unique[word] += 1\n\n        elif y[i] == \"E\":\n            count_e += 1\n            for word in word_li:\n                count_dict[\"E\"] += 1\n                if word not in dict_e:\n                    dict_e[word] = 1\n                else:\n                    dict_e[word] += 1 \n                if word not in unique:\n                    unique[word] = 1\n                else:\n                    unique[word] += 1\n\n        elif y[i] == \"V\":\n            count_v += 1\n            for word in word_li:\n                count_dict[\"V\"] += 1\n                if word not in dict_v:\n                    dict_v[word] = 1\n                else:\n                    dict_v[word]+=1 \n                if word not in unique:\n                    unique[word] = 1\n                else:\n                    unique[word] += 1\n    # Obtain Prior Probability of Classes\n    prior_dict = {}\n    prior_dict[\"A\"] = math.log(count_a / len(X))\n    prior_dict[\"B\"] = math.log(count_b / len(X))\n    prior_dict[\"V\"] = math.log(count_v / len(X))\n    prior_dict[\"E\"] = math.log(count_e / len(X))\n    \n    return prior_dict, dict_a, dict_b, dict_v, dict_e, unique, count_dict\n\ndef predict(X, prior_dict, dict_a, dict_b, dict_v, dict_e, unique, count_dict):\n    # Predicting outcomes \n    outcome = [[] for x in range(len(X))]\n    target = [\"A\", \"B\", \"E\", \"V\"]\n    for i in range(len(X)):\n        P_AX = prior_dict[\"A\"]\n        P_BX = prior_dict[\"B\"]\n        P_EX = prior_dict[\"E\"]\n        P_VX = prior_dict[\"V\"]\n        unseen = 0\n        for word in X[i].split():\n            if word not in unique:\n                unseen += 1\n            if word in dict_a:\n                P_AX = P_AX + math.log((dict_a[word]+1) / (count_dict[\"A\"]+ len(unique) + unseen))\n            else:\n                P_AX = P_AX + math.log(1/(count_dict[\"A\"] + len(unique)+ unseen))\n\n            if word in dict_b:\n                P_BX = P_BX + math.log((dict_b[word]+1) / (count_dict[\"B\"]+ len(unique) + unseen))\n            else:\n                P_BX = P_BX + math.log(1/(count_dict[\"B\"] + len(unique)+ unseen))\n\n            if word in dict_e:\n                P_EX = P_EX + math.log((dict_e[word]+1)/(count_dict[\"E\"]+ len(unique) + unseen))\n            else:\n                P_EX = P_EX + math.log(1/(count_dict[\"E\"] + len(unique) + unseen))\n\n            if word in dict_v:\n                P_VX = P_VX + math.log((dict_v[word]+1)/(count_dict[\"V\"]+ len(unique) + unseen))\n            else:\n                P_VX = P_VX + math.log(1/(count_dict[\"V\"] + len(unique) + unseen))\n\n        probs = [P_AX, P_BX, P_EX, P_VX]\n        outcome[i] = target[probs.index(max(probs))]\n    return outcome\n\ndef evaluate(result, y):\n    score = len(y)\n    for i in range(len(y)):\n        if result[i] != y[i]:\n            score -= 1\n    return score/len(y)\n\n# Evaluate\nind = round(len(X)*0.7)\nX_train = X[:ind]\nX_val = X[ind:]\ny_train = y[:ind]\ny_val = y[ind:]\n\nprior_dict, dict_a, dict_b, dict_v, dict_e, unique, count_dict = train(X_train, y_train)\nresult = predict(X_val, prior_dict, dict_a, dict_b, dict_v, dict_e, unique, count_dict)\nevaluate(result, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Complement class version\ndef train(X,y):\n    \n    # Obtain number of each class\n    count_a = 0\n    count_b = 0\n    count_v = 0\n    count_e = 0\n    unique = {}\n    word_dict = {}\n    # Obtain number of words in each class\n    count_dict = {\"A\":0, \"B\":0, \"E\":0, \"V\":0}\n\n    for i in range(len(X)):\n        word_li = X[i].split()\n        for word in word_li:\n            if word not in word_dict:\n                word_dict[word]={\"A\":0, \"B\":0, \"V\":0, \"E\":0}\n            if y[i] == \"A\":\n                word_dict[word][\"A\"] += 1\n                count_dict[\"A\"] += 1\n            elif y[i] == \"B\":\n                word_dict[word][\"B\"] += 1\n                count_dict[\"B\"] += 1\n            elif y[i] == \"E\":\n                word_dict[word][\"E\"] += 1\n                count_dict[\"E\"] += 1\n            elif y[i] == \"V\":\n                word_dict[word][\"V\"] += 1\n                count_dict[\"V\"] += 1\n                \n    # Obtain Prior Probability of Classes\n    for i in range(len(X)):\n        if y[i] == \"A\":\n            count_a += 1\n        elif y[i] == \"B\":\n            count_b += 1\n        elif y[i] == \"E\":\n            count_e += 1  \n        elif y[i] == \"V\":\n            count_v += 1\n            \n    prior_dict = {}\n    prior_dict[\"A\"] = math.log(count_a / len(X))\n    prior_dict[\"B\"] = math.log(count_b / len(X))\n    prior_dict[\"V\"] = math.log(count_v / len(X))\n    prior_dict[\"E\"] = math.log(count_e / len(X))            \n    \n    return prior_dict, word_dict, count_dict\n\ndef predict(X, prior_dict, word_dict, count_dict):\n    # Predicting outcomes \n    outcome = [[] for x in range(len(X))]\n    target = [\"A\", \"B\", \"E\", \"V\"]\n    for i in range(len(X)):\n        unseen = 0\n        P_AX = prior_dict[\"A\"]\n        P_BX = prior_dict[\"B\"]\n        P_EX = prior_dict[\"E\"]\n        P_VX = prior_dict[\"V\"]\n        for word in X[i].split():\n            if word not in word_dict:\n                P_AX = P_AX - math.log(1/(count_dict[\"B\"]+count_dict[\"V\"]+count_dict[\"E\"]+len(word_dict)))\n                P_BX = P_BX - math.log(1/(count_dict[\"A\"]+count_dict[\"V\"]+count_dict[\"E\"]+len(word_dict)))\n                P_VX = P_VX - math.log(1/(count_dict[\"A\"]+count_dict[\"B\"]+count_dict[\"E\"]+len(word_dict)))\n                P_EX = P_EX - math.log(1/(count_dict[\"A\"]+count_dict[\"B\"]+count_dict[\"V\"]+len(word_dict)))\n            else:\n                P_AX = P_AX - math.log((word_dict[word][\"B\"]+word_dict[word][\"V\"]+word_dict[word][\"E\"]+1) / (count_dict[\"B\"]+count_dict[\"V\"]+count_dict[\"E\"]+len(word_dict)))\n                P_BX = P_BX - math.log((word_dict[word][\"A\"]+word_dict[word][\"V\"]+word_dict[word][\"E\"]+1) / (count_dict[\"A\"]+count_dict[\"V\"]+count_dict[\"E\"]+len(word_dict)))\n                P_VX = P_VX - math.log((word_dict[word][\"A\"]+word_dict[word][\"B\"]+word_dict[word][\"E\"]+1) / (count_dict[\"A\"]+count_dict[\"B\"]+count_dict[\"E\"]+len(word_dict)))\n                P_EX = P_EX - math.log((word_dict[word][\"A\"]+word_dict[word][\"B\"]+word_dict[word][\"V\"]+1) / (count_dict[\"A\"]+count_dict[\"B\"]+count_dict[\"V\"]+len(word_dict)))\n\n        probs = [P_AX, P_BX, P_EX, P_VX]\n        outcome[i] = target[probs.index(max(probs))]\n    return outcome\n\ndef evaluate(result, y):\n    score = len(y)\n    for i in range(len(y)):\n        if result[i] != y[i]:\n            score -= 1\n    return score/len(y)\n\n# Evaluate\nind = round(len(X)*0.7)\nX_train = X[:ind]\nX_val = X[ind:]\ny_train = y[:ind]\ny_val = y[ind:]\n\n'''\nprior_dict, word_dict, count_dict = train(X_train, y_train)\nresult = predict(X_val, prior_dict, word_dict, count_dict)\nevaluate(result, y_val)\n'''\nprior_dict, word_dict, count_dict = train(X, y)\nresult = predict(X_test, prior_dict, word_dict, count_dict)\nidh = [i+1 for i in range(1000)]\nnp.savetxt(\"shon866_A3_final_new.csv\", np.c_[idh,result],fmt='%s',header=\"id,class\", comments='', delimiter=',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Complement class + IDF version\ndef train(X,y):\n    \n    # Obtain number of each class\n    count_a = 0\n    count_b = 0\n    count_v = 0\n    count_e = 0\n    unique = {}\n    word_dict = {}\n    # Obtain number of words in each class\n    count_dict = {\"A\":0, \"B\":0, \"E\":0, \"V\":0}\n\n    for i in range(len(X)):\n        word_li = X[i].split()\n        for word in word_li:\n            if word not in word_dict:\n                word_dict[word]={\"A\":0, \"B\":0, \"V\":0, \"E\":0}\n            if y[i] == \"A\":\n                word_dict[word][\"A\"] += 1\n                count_dict[\"A\"] += 1\n            elif y[i] == \"B\":\n                word_dict[word][\"B\"] += 1\n                count_dict[\"B\"] += 1\n            elif y[i] == \"E\":\n                word_dict[word][\"E\"] += 1\n                count_dict[\"E\"] += 1\n            elif y[i] == \"V\":\n                word_dict[word][\"V\"] += 1\n                count_dict[\"V\"] += 1\n            if word not in unique:\n                    unique[word] = np.zeros((4000,), dtype=int)\n                    unique[word][i] = 1\n            else:\n                if unique[word][i] == 0:\n                    unique[word][i] = 1\n                \n    # Obtain Prior Probability of Classes\n    for i in range(len(X)):\n        if y[i] == \"A\":\n            count_a += 1\n        elif y[i] == \"B\":\n            count_b += 1\n        elif y[i] == \"E\":\n            count_e += 1  \n        elif y[i] == \"V\":\n            count_v += 1\n            \n    prior_dict = {}\n    prior_dict[\"A\"] = math.log(count_a / len(X))\n    prior_dict[\"B\"] = math.log(count_b / len(X))\n    prior_dict[\"V\"] = math.log(count_v / len(X))\n    prior_dict[\"E\"] = math.log(count_e / len(X))            \n    \n    return prior_dict, word_dict, count_dict, unique\n\ndef predict(X, prior_dict, word_dict, count_dict, unique):\n    # Predicting outcomes \n    outcome = [[] for x in range(len(X))]\n    target = [\"A\", \"B\", \"E\", \"V\"]\n    for i in range(len(X)):\n        unseen = 0\n        P_AX = prior_dict[\"A\"]\n        P_BX = prior_dict[\"B\"]\n        P_EX = prior_dict[\"E\"]\n        P_VX = prior_dict[\"V\"]\n        for word in X[i].split():\n            if word not in word_dict:\n                P_AX = P_AX - math.log(1/(count_dict[\"B\"]+count_dict[\"V\"]+count_dict[\"E\"]+len(word_dict)))\n                P_BX = P_BX - math.log(1/(count_dict[\"A\"]+count_dict[\"V\"]+count_dict[\"E\"]+len(word_dict)))\n                P_VX = P_VX - math.log(1/(count_dict[\"A\"]+count_dict[\"B\"]+count_dict[\"E\"]+len(word_dict)))\n                P_EX = P_EX - math.log(1/(count_dict[\"A\"]+count_dict[\"B\"]+count_dict[\"V\"]+len(word_dict)))\n            else:\n                P_AX = P_AX - math.log(((word_dict[word][\"B\"]+word_dict[word][\"V\"]+word_dict[word][\"E\"])*math.log((4000/unique[word].sum()))+1) / (count_dict[\"B\"]+count_dict[\"V\"]+count_dict[\"E\"]+len(word_dict)))\n                P_BX = P_BX - math.log(((word_dict[word][\"A\"]+word_dict[word][\"V\"]+word_dict[word][\"E\"])*math.log((4000/unique[word].sum()))+1) / (count_dict[\"A\"]+count_dict[\"V\"]+count_dict[\"E\"]+len(word_dict)))\n                P_VX = P_VX - math.log(((word_dict[word][\"A\"]+word_dict[word][\"B\"]+word_dict[word][\"E\"])*math.log((4000/unique[word].sum()))+1) / (count_dict[\"A\"]+count_dict[\"B\"]+count_dict[\"E\"]+len(word_dict)))\n                P_EX = P_EX - math.log(((word_dict[word][\"A\"]+word_dict[word][\"B\"]+word_dict[word][\"V\"])*math.log((4000/unique[word].sum()))+1) / (count_dict[\"A\"]+count_dict[\"B\"]+count_dict[\"V\"]+len(word_dict)))\n\n        probs = [P_AX, P_BX, P_EX, P_VX]\n        outcome[i] = target[probs.index(max(probs))]\n    return outcome\n\ndef evaluate(result, y):\n    score = len(y)\n    for i in range(len(y)):\n        if result[i] != y[i]:\n            score -= 1\n    return score/len(y)\n\n# Evaluate\nind = round(len(X)*0.7)\nX_train = X[:ind]\nX_val = X[ind:]\ny_train = y[:ind]\ny_val = y[ind:]\n\nprior_dict, word_dict, count_dict, unique = train(X_train, y_train)\nresult = predict(X_val, prior_dict, word_dict, count_dict, unique)\nprint(evaluate(result, y_val))\n\n#---------------------------------------------------------------------------------------------------\n#prior_dict, word_dict, count_dict, unique = train(X, y)\n#result = predict(X_test, prior_dict, word_dict, count_dict, unique) #TRAINING ON TEST SET NOW !!!!!\n#idh = [i+1 for i in range(1000)]\n#np.savetxt(\"shon866_A3_final.csv\", np.c_[idh,result],fmt='%s',header=\"id,class\", comments='', delimiter=',')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}